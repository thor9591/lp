import pandas as pd 
import numpy as np 
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression 
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error



df = pd.read_csv("C:/Users/UDDHAV ILHE/Desktop/uber.csv")

print(df)

print(df.head())

print(df.info())

print(df.columns)

df = df.drop(['Unnamed: 0',	'key'],  axis=1)

print(df.head())

print(df.shape)

print(df.describe())

print(df.isnull().sum())

df['dropoff_latitude'].fillna(value=df['dropoff_latitude'].mean(), inplace=True)
df['dropoff_longitude'].fillna(value=df['dropoff_longitude'].median(), inplace=True)

print(df.isnull().sum())

print(df.dtypes)

df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')

print(df.dtypes)

#  to  segregate  each  time  of   date  and  I ice
df=	df.assign(hour=df['pickup_datetime'].dt.hour,
    day=df['pickup_datetime'].dt.day,
    month=df['pickup_datetime'].dt.month, 
    year=df['pickup_datetime'].dt.year, 
dayofweek=df['pickup_datetime'].dt.dayofweek)


df = df.drop('pickup_datetime',axis=1)

print(df.plot(kind="box", subplots=True, layout=(7, 2), figsize=(15, 20)))


# Us ing   the    ZntenÂ§uanti L e Range   to   fi L L   the    va Lues
def remove_outlier(df1, col):
    Q1 = df1[col].quantile(0.25)
    Q3 = df1[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_whisker = Q1 - 1.5 * IQR 
    upper_whisker = Q3 + 1.5 * IQR
    df[col] = np.clip(df1[col], lower_whisker, upper_whisker) 
    return df1

def treat_outliers_all(df1, col_list) :
    for c in col_list:
        df1 = remove_outlier(df, c)
    return df1

df = treat_outliers_all(df, df.iloc[:, 0::])

# Boxp Lot shows that  dataset  is   free  from outL hers
df.plot(kind="box", subplots=True, layout=(7, 2), figsize=(15, 20))
plt.show()

import haversine as hs
travel_dist = []
for pos in range(len(df['pickup_longitude'])):
    longl, latil, long2, lati2 = [ df['pickup_longitude'][pos], 
                            df['pickup_latitude'][pos], 
                            df['dropoff_longitude'][pos], 
                            df['dropoff_latitude'][pos]]
locl = (latil, longl)
loc2 = (lati2, long2)
    
c = hs.haversine(locl, loc2)
travel_dist.append(c)   
print(travel_dist)

travel_dist = 2000000
df['dist_travel_km'] = travel_dist 
print(df.head())


#uber desn't travel over 130 kms so minimize the distance
df = df.loc[(df['dist_travel_km'] >= 1) & (df['dist_travel_km'] <= 130)]
print("Remaining observations in the dataset:", df.shape)

# Finding incorrect Latitude (Less than or greater than 90) 
# and Longitude (Less than or greater than 180)
incorrect_coordinates = df.loc[
    (df['pickup_latitude'] > 90) | (df['pickup_latitude'] < -90) |
    (df['dropoff_latitude'] > 90) | (df['dropoff_latitude'] < -90) |
    (df['pickup_longitude'] > 180) | (df['pickup_longitude'] < -180) |
    (df['dropoff_longitude'] > 180) | (df['dropoff_longitude'] < -180)]


# Dropping incorrect coordinates
df.drop(incorrect_coordinates.index, inplace=True, errors='ignore')

#function to Find Correlation
corr = df.corr()

# Function to find the correlation (Display the correlation using a heatmap)
fig, axis = plt.subplots(figsize=(10, 6))
sns.heatmap(corr, annot=True)
plt.show()

# Dividing the dataset into feature and Target values

x=df.drop("fare_amount", axis=1)
y=df['fare_amount']
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)
x_train.head()


################ Linear Regression #######################

# Import Linear Regression from scikit-learn
regression = LinearRegression()

# Train the model using features and target
regression.fit(x_train, y_train)

# To find the linear intercept
intercept = regression.intercept_
print("Intercept:", intercept)

# To find the linear coefficients
coefficients = regression.coef_
print("Coefficients:", coefficients)

# Predict the target values
prediction = regression.predict(x_test)
print("Predictions:", prediction)

# Model Evaluation using R2, Mean Squared Error, Root Mean Squared Error
R2 = r2_score(y_test, prediction)
MSE = mean_squared_error(y_test, prediction)
RMSE = np.sqrt(MSE)

print("R2 is : ", R2)
print("Mean Squared Error is :", MSE) 
print("Root Mean Squared Error is : ", RMSE)

################ Random Forest#######################
# Here n_estimation Means number of trees you want to
# build before making the prediction

rf = RandomForestRegressor(n_estimators=100)
rf.fit(x_train, y_train)

# Predictions
y_pred = rf.predict(x_test)

print(y_pred)

# Metrics Evoluation using R2, Mean Square Error
# Root Mean Squared Error

R2 = r2_score(y_test, y_pred)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print("R2 is:", R2)
print("Mean Squared Error is:", MSE)
print("Root Mean Squared Error is:", RMSE)




